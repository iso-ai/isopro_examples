{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Simulator\n",
    "\n",
    "This notebook demonstrates the usage of the Conversation Simulator from the isopro package. It simulates conversations between an AI assistant (either Claude or GPT-4) and various user personas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from isopro.conversation_simulation.conversation_simulator import ConversationSimulator\n",
    "from isopro.conversation_simulation.custom_persona import create_custom_persona\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up logging\n",
    "log_directory = \"logs\"\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "log_file = os.path.join(log_directory, \"conversation_simulator.log\")\n",
    "\n",
    "# Create a rotating file handler\n",
    "file_handler = RotatingFileHandler(log_file, maxBytes=1024*1024, backupCount=5)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "# Create a console handler\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_formatter)\n",
    "\n",
    "# Set up the logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Next, let's define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(content, filename):\n",
    "    \"\"\"Save the output content to a file.\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def get_user_choice():\n",
    "    \"\"\"Get user's choice of AI model.\"\"\"\n",
    "    while True:\n",
    "        choice = input(\"Choose AI model (claude/openai): \").lower()\n",
    "        if choice in ['claude', 'openai']:\n",
    "            return choice\n",
    "        print(\"Invalid choice. Please enter 'claude' or 'openai'.\")\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Simulation Function\n",
    "\n",
    "Now, let's define our main simulation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation():\n",
    "    # Get user's choice of AI model\n",
    "    ai_choice = get_user_choice()\n",
    "\n",
    "    # Set up the appropriate model and API key\n",
    "    if ai_choice == 'claude':\n",
    "        model = \"claude-3-opus-20240229\"\n",
    "        os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        ai_name = \"Claude\"\n",
    "    else:  # openai\n",
    "        model = \"gpt-4-1106-preview\"\n",
    "        os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "        ai_name = \"GPT-4 Turbo\"\n",
    "\n",
    "    # Initialize the ConversationSimulator\n",
    "    simulator = ConversationSimulator(\n",
    "        ai_prompt=f\"You are {ai_name}, an AI assistant created to be helpful, harmless, and honest. You are a customer service agent for a tech company. Respond politely and professionally.\"\n",
    "    )\n",
    "\n",
    "    output_content = f\"Conversation Simulator using {ai_name} model: {model}\\n\\n\"\n",
    "\n",
    "    # Run simulations with different personas\n",
    "    personas = [\"upset\", \"human_request\", \"inappropriate\", \"incomplete_info\"]\n",
    "    \n",
    "    for persona in personas:\n",
    "        logger.info(f\"Running simulation with {persona} persona using {ai_name}\")\n",
    "        conversation_history = simulator.run_simulation(persona, num_turns=3)\n",
    "        \n",
    "        output_content += f\"\\nConversation with {persona} persona:\\n\"\n",
    "        for message in conversation_history:\n",
    "            output_line = f\"{message['role'].capitalize()}: {message['content']}\\n\"\n",
    "            output_content += output_line\n",
    "            logger.debug(output_line.strip())\n",
    "        output_content += \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "\n",
    "    # Create and run a simulation with a custom persona\n",
    "    custom_persona_name = \"Techie Customer\"\n",
    "    custom_characteristics = [\"tech-savvy\", \"impatient\", \"detail-oriented\"]\n",
    "    custom_message_templates = [\n",
    "        \"I've tried rebooting my device, but the error persists. Can you help?\",\n",
    "        \"What's the latest update on the cloud service outage?\",\n",
    "        \"I need specifics on the API rate limits for the enterprise plan.\",\n",
    "        \"The latency on your servers is unacceptable. What's being done about it?\",\n",
    "        \"Can you explain the technical details of your encryption method?\"\n",
    "    ]\n",
    "\n",
    "    logger.info(f\"Running simulation with custom persona: {custom_persona_name} using {ai_name}\")\n",
    "    custom_conversation = simulator.run_custom_simulation(\n",
    "        custom_persona_name,\n",
    "        custom_characteristics,\n",
    "        custom_message_templates,\n",
    "        num_turns=3\n",
    "    )\n",
    "\n",
    "    output_content += f\"\\nConversation with {custom_persona_name}:\\n\"\n",
    "    for message in custom_conversation:\n",
    "        output_line = f\"{message['role'].capitalize()}: {message['content']}\\n\"\n",
    "        output_content += output_line\n",
    "        logger.debug(output_line.strip())\n",
    "\n",
    "    # Save the output to a file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_directory = \"output\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    output_file = os.path.join(output_directory, f\"{ai_name.lower()}_conversation_output_{timestamp}.txt\")\n",
    "    save_output(output_content, output_file)\n",
    "    logger.info(f\"Output saved to {output_file}\")\n",
    "\n",
    "    return output_content\n",
    "\n",
    "print(\"Main simulation function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Simulation\n",
    "\n",
    "Now we're ready to run the simulation. This cell will prompt you to choose between Claude and GPT-4, then run the simulation and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_output = run_simulation()\n",
    "print(simulation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Results\n",
    "\n",
    "After running the simulation, you can analyze the results here. For example, you might want to count the number of times certain phrases or words were used, or calculate the average length of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example analysis: Count the number of apologies\n",
    "apology_count = simulation_output.lower().count(\"sorry\") + simulation_output.lower().count(\"apologi\")\n",
    "print(f\"Number of apologies: {apology_count}\")\n",
    "\n",
    "# Example analysis: Average length of AI responses\n",
    "ai_responses = [line.split(\": \", 1)[1] for line in simulation_output.split(\"\\n\") if line.startswith(\"Assistant: \")]\n",
    "avg_response_length = sum(len(response.split()) for response in ai_responses) / len(ai_responses)\n",
    "print(f\"Average length of AI responses: {avg_response_length:.2f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to use the Conversation Simulator from the isopro package. You can modify the personas, adjust the number of turns, or add your own analysis to further explore the capabilities of the AI models in customer service scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
