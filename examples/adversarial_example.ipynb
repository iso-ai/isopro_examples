{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Simulation Notebook\n",
    "\n",
    "This notebook demonstrates how to run an adversarial simulation against a language model (in this case, Claude) and analyze the results.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we'll import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "from isopro.adversarial_simulation import AdversarialSimulator, AdversarialEnvironment\n",
    "from isopro.utils.analyze_adversarial_sim import analyze_adversarial_results, summarize_adversarial_impact\n",
    "from isopro.agents.ai_agent import AI_Agent\n",
    "import anthropic\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Classes and Functions\n",
    "\n",
    "Now, we'll define our ClaudeAgent class and some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClaudeAgent(AI_Agent):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.client = anthropic.Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "    def run(self, input_data):\n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-3-opus-20240229\",\n",
    "            max_tokens=100,\n",
    "            messages=[{\"role\": \"user\", \"content\": input_data['text']}]\n",
    "        )\n",
    "        return response.content[0].text\n",
    "\n",
    "    def step(self, sim_state):\n",
    "        sim_state['output'] = self.run(sim_state)\n",
    "        return sim_state\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "def save_scores(output_dir: str, run_id: str, analysis_results: dict) -> None:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, f\"adv-{run_id}.json\")\n",
    "    \n",
    "    try:\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(analysis_results, f, indent=2, cls=NumpyEncoder)\n",
    "        \n",
    "        logging.info(f\"Saved analysis results to {output_file}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving analysis results: {str(e)}\")\n",
    "\n",
    "def get_sample_inputs() -> List[str]:\n",
    "    return [\n",
    "        \"What is the capital of France?\",\n",
    "        \"How does photosynthesis work?\",\n",
    "        \"Explain the theory of relativity.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Adversarial Simulation\n",
    "\n",
    "Now we'll set up and run our adversarial simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation():\n",
    "    run_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    logger.info(f\"Starting adversarial simulation run {run_id}\")\n",
    "\n",
    "    claude_agent = ClaudeAgent(\"Claude Agent\")\n",
    "\n",
    "    # Create the AdversarialEnvironment\n",
    "    adv_env = AdversarialEnvironment(\n",
    "        agent_wrapper=claude_agent,\n",
    "        num_adversarial_agents=2,\n",
    "        attack_types=[\"textbugger\", \"deepwordbug\"],\n",
    "        attack_targets=[\"input\", \"output\"]\n",
    "    )\n",
    "\n",
    "    # Set up the adversarial simulator with the environment\n",
    "    simulator = AdversarialSimulator(adv_env)\n",
    "\n",
    "    input_data = get_sample_inputs()\n",
    "\n",
    "    logger.info(\"Starting adversarial simulation...\")\n",
    "    simulation_results = simulator.run_simulation(input_data, num_steps=1)\n",
    "\n",
    "    logger.info(\"Analyzing simulation results...\")\n",
    "    analysis_results = analyze_adversarial_results(simulation_results)\n",
    "\n",
    "    summary = summarize_adversarial_impact(analysis_results)\n",
    "\n",
    "    print(\"\\nAdversarial Simulation Summary:\")\n",
    "    print(summary)\n",
    "\n",
    "    output_dir = \"output\"\n",
    "    save_scores(output_dir, run_id, analysis_results)\n",
    "\n",
    "    logger.info(\"Simulation complete.\")\n",
    "    \n",
    "    return simulation_results, analysis_results\n",
    "\n",
    "# Run the simulation\n",
    "simulation_results, analysis_results = run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and Visualize Results\n",
    "\n",
    "Now that we have our results, let's analyze and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_changes(analysis_results):\n",
    "    metrics = ['bleu', 'rouge-1', 'rouge-2', 'rouge-l', 'perplexity', 'coherence']\n",
    "    changes = [analysis_results[f'{metric}_change'] for metric in metrics]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=metrics, y=changes)\n",
    "    plt.title('Changes in Metrics After Adversarial Attacks')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Percentage Change')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "plot_metric_changes(analysis_results)\n",
    "\n",
    "# Display original and perturbed inputs and outputs\n",
    "for i, result in enumerate(simulation_results):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Original Input: {result['original_input']}\")\n",
    "    print(f\"Perturbed Input: {result['perturbed_input']}\")\n",
    "    print(f\"Original Output: {result['original_output']}\")\n",
    "    print(f\"Perturbed Output: {result['perturbed_output']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to run an adversarial simulation against a language model and analyze the results. The simulation applies various adversarial attacks to the input or output of the model and measures the impact on different metrics.\n",
    "\n",
    "Key observations:\n",
    "1. The changes in different metrics (BLEU, ROUGE, perplexity, coherence) show how the adversarial attacks affect the model's performance.\n",
    "2. By comparing the original and perturbed inputs and outputs, we can see how the attacks modify the text and how the model's responses change as a result.\n",
    "\n",
    "This information can be used to assess the robustness of the language model against adversarial attacks and identify areas for improvement in the model's defenses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smooth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e35b4d35af899f01dc238e082b97509c22792197b4b3ae814b774a24a240ad24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
