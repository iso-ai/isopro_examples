{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# isopro Tutorial: Orchestrator, Evaluator, and Evaluation Modules\n",
    "\n",
    "This notebook will guide you through using the `isopro` package, focusing on the orchestrator, evaluator, and evaluation modules. We'll cover installation, setup, and usage examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, let's install the `isopro` package. Run the following cell to install it using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install isopro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup\n",
    "\n",
    "Now, let's import the necessary modules and set up our environment. We'll need to set our API keys for OpenAI and Anthropic. In a production environment, you should use environment variables for these keys. For this notebook, we'll set them directly (but remember not to share your notebook with these keys included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from isopro.orchestration_simulation import OrchestrationEnv\n",
    "from isopro.orchestration_simulation.components import LLaMAAgent, AnalysisAgent, WritingAgent\n",
    "from isopro.orchestration_simulation.evaluator import Evaluator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access API keys from environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating the Orchestration Environment\n",
    "\n",
    "Let's create our orchestration environment and add our agents to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the orchestration environment\n",
    "env = OrchestrationEnv()\n",
    "\n",
    "# Add agents to the environment\n",
    "env.add_component(LLaMAAgent(\"Research\", \"conduct thorough research on the impact of artificial intelligence on job markets in the next decade\"))\n",
    "env.add_component(AnalysisAgent(\"Analysis\"))\n",
    "env.add_component(WritingAgent(\"Writing\"))\n",
    "\n",
    "print(\"Orchestration environment created with agents added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defining the Task\n",
    "\n",
    "Now, let's define the task that our agents will work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Prepare a comprehensive report on the impact of artificial intelligence on job markets in the next decade.\"\n",
    "print(f\"Task defined: {task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running Simulations in Different Modes\n",
    "\n",
    "We'll now run our simulation in different modes: parallel, sequence, and node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['parallel', 'sequence', 'node']\n",
    "results = {}\n",
    "\n",
    "for mode in modes:\n",
    "    print(f\"\\nRunning simulation in {mode} mode...\")\n",
    "    result = env.run_simulation(mode=mode, input_data={'task': task, 'run_order': 'first'})\n",
    "    results[mode] = result\n",
    "    print(f\"Simulation in {mode} mode completed.\")\n",
    "\n",
    "print(\"\\nAll simulations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating the Results\n",
    "\n",
    "Now that we have our results, let's use the Evaluator to determine which mode performed best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Evaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a86bfe25b9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEvaluation complete. The best execution mode for this task was: {best_mode}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Evaluator' is not defined"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "best_mode = evaluator.evaluate(results)\n",
    "\n",
    "print(f\"\\nEvaluation complete. The best execution mode for this task was: {best_mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Examining the Results\n",
    "\n",
    "Let's take a closer look at the results from each mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode, result in results.items():\n",
    "    print(f\"\\nResults for {mode} mode:\")\n",
    "    print(f\"Execution Time: {result.get('execution_time', 'N/A')} seconds\")\n",
    "    print(f\"Memory Usage: {result.get('memory_usage', 'N/A')} MB\")\n",
    "    print(f\"Output Sample: {result.get('output', 'N/A')[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this tutorial, we've learned how to:\n",
    "1. Set up the isopro package\n",
    "2. Create an orchestration environment and add agents\n",
    "3. Run simulations in different modes\n",
    "4. Use the Evaluator to determine the best execution mode\n",
    "5. Examine the results of our simulations\n",
    "\n",
    "This demonstrates the power and flexibility of the isopro package for orchestrating AI agents and evaluating their performance in different execution modes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smooth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e35b4d35af899f01dc238e082b97509c22792197b4b3ae814b774a24a240ad24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
